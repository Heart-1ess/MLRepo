{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cabe4f4-93e7-4003-9340-2ff51ea9db04",
   "metadata": {},
   "source": [
    "任务: 泰坦尼克号乘客生存预测\n",
    "\n",
    "流程: \n",
    "```\n",
    "1. 数据读取与清洗\n",
    "2. 特征工程（提取特征与细化）\n",
    "3. 模型训练\n",
    "4. 模型评估\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "47ccc857-c632-47cc-ac25-e58e729cdcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b50f51c-e186-4ccf-8c9e-d0f3affe26d2",
   "metadata": {},
   "source": [
    "数据读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dd9a807a-5392-4b04-a09b-59e924debe9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/data/ys_data/titanic/train.csv\")\n",
    "test = pd.read_csv(\"/data/ys_data/titanic/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62642742-5eff-4ab3-8fa4-5c90e8d1c17e",
   "metadata": {},
   "source": [
    "数据清洗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "867e2e92-2862-4304-b192-c4fa4adfa4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 合并两个数据集查看整体数据集信息，合并数据集并忽略缺失值\n",
    "full = data._append(test, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "71edd4c2-6aed-45ea-9437-462faaab5e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1309 entries, 0 to 1308\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  1309 non-null   int64  \n",
      " 1   Survived     891 non-null    float64\n",
      " 2   Pclass       1309 non-null   int64  \n",
      " 3   Name         1309 non-null   object \n",
      " 4   Sex          1309 non-null   object \n",
      " 5   Age          1046 non-null   float64\n",
      " 6   SibSp        1309 non-null   int64  \n",
      " 7   Parch        1309 non-null   int64  \n",
      " 8   Ticket       1309 non-null   object \n",
      " 9   Fare         1308 non-null   float64\n",
      " 10  Cabin        295 non-null    object \n",
      " 11  Embarked     1307 non-null   object \n",
      "dtypes: float64(3), int64(4), object(5)\n",
      "memory usage: 122.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# 查看数据集整体情况，查看缺失数据并规划数据清洗\n",
    "full.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9634993-ee5e-4872-a1fb-42a7dfa4a6ad",
   "metadata": {},
   "source": [
    "数据清洗的方法：\r\n",
    "\r\n",
    "A如果是数值型，用平均数取代\r\n",
    "\r\n",
    "B如果是分类数据，用最常见的类别取代\r\n",
    "\r\n",
    "C使用模型预测缺失值，例如：K-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "91d1ccef-bb4a-4a21-8e06-941ee5426b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用均值填充Age和Fare\n",
    "full[\"Age\"] = full[\"Age\"].fillna(full[\"Age\"].mean())\n",
    "full[\"Fare\"] = full[\"Fare\"].fillna(full[\"Fare\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0ce5a96f-1bcd-4844-85d8-3f7b31d99e5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embarked\n",
       "S    914\n",
       "C    270\n",
       "Q    123\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看Embarked常见类别\n",
    "full[\"Embarked\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0bf5418d-9239-4084-96e3-a76f44628485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用常见的类别填充Embarked\n",
    "full[\"Embarked\"] = full[\"Embarked\"].fillna(\"S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "978c17f3-feb3-4571-b718-5aa4d908525a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cabin一列缺失较多，暂填充为u，代表未知\n",
    "full[\"Cabin\"] = full[\"Cabin\"].fillna(\"u\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5b9114ae-72f3-4aaf-80dd-a663b377a3e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1309 entries, 0 to 1308\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  1309 non-null   int64  \n",
      " 1   Survived     891 non-null    float64\n",
      " 2   Pclass       1309 non-null   int64  \n",
      " 3   Name         1309 non-null   object \n",
      " 4   Sex          1309 non-null   object \n",
      " 5   Age          1309 non-null   float64\n",
      " 6   SibSp        1309 non-null   int64  \n",
      " 7   Parch        1309 non-null   int64  \n",
      " 8   Ticket       1309 non-null   object \n",
      " 9   Fare         1309 non-null   float64\n",
      " 10  Cabin        1309 non-null   object \n",
      " 11  Embarked     1309 non-null   object \n",
      "dtypes: float64(3), int64(4), object(5)\n",
      "memory usage: 122.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# 填充完成后查看数据集\n",
    "full.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d538200-b0d5-424b-9922-2879794679f7",
   "metadata": {},
   "source": [
    "特征提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b1800a86-92d0-4eac-bb3f-66fb43a16757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对性别进行替换（male->1, female->2）\n",
    "sex_mapDict = { \"male\" : 1, \n",
    "               \"female\" : 0}\n",
    "full[\"Sex\"] = full[\"Sex\"].map(sex_mapDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6797e15f-0700-4a38-8d70-b7e3bdf864dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       0\n",
       "2       0\n",
       "3       0\n",
       "4       1\n",
       "       ..\n",
       "1304    1\n",
       "1305    0\n",
       "1306    1\n",
       "1307    1\n",
       "1308    1\n",
       "Name: Sex, Length: 1309, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full[\"Sex\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fded29ae-09cf-480e-8614-b5add131035d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_extraction\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DictVectorizer\n\u001b[1;32m      4\u001b[0m transfer \u001b[38;5;241m=\u001b[39m DictVectorizer()\n\u001b[0;32m----> 5\u001b[0m embarked \u001b[38;5;241m=\u001b[39m \u001b[43mtransfer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfull\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEmbarked\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/MachineLearning/lib/python3.8/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/envs/MachineLearning/lib/python3.8/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/MachineLearning/lib/python3.8/site-packages/sklearn/feature_extraction/_dict_vectorizer.py:313\u001b[0m, in \u001b[0;36mDictVectorizer.fit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_transform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    291\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Learn a list of feature name -> indices mappings and transform X.\u001b[39;00m\n\u001b[1;32m    292\u001b[0m \n\u001b[1;32m    293\u001b[0m \u001b[38;5;124;03m    Like fit(X) followed by transform(X), but does not require\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;124;03m        Feature vectors; always 2-d.\u001b[39;00m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 313\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfitting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/MachineLearning/lib/python3.8/site-packages/sklearn/feature_extraction/_dict_vectorizer.py:223\u001b[0m, in \u001b[0;36mDictVectorizer._transform\u001b[0;34m(self, X, fitting)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;66;03m# collect all the possible feature names and build sparse matrix at\u001b[39;00m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;66;03m# same time\u001b[39;00m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m X:\n\u001b[0;32m--> 223\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f, v \u001b[38;5;129;01min\u001b[39;00m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m():\n\u001b[1;32m    224\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    225\u001b[0m             feature_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseparator, v)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "# Embarked转化为one-hot编码（字典特征提取）\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "transfer = DictVectorizer()\n",
    "embarked = transfer.fit_transform(full[\"Embarked\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5ef3e4-1f20-4e4a-a7a8-415f147045ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
